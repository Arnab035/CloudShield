{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zechengh/.local/lib/python3.6/site-packages/numba/errors.py:137: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Ins\n",
      "1 L1D read access (# load)\n",
      "2 L1D read miss\n",
      "3 L1D write access (# store)\n",
      "4 L1D write miss\n",
      "5 L1D prefetch miss\n",
      "6 L1I read miss\n",
      "7 LLC read access\n",
      "8 LLC read miss\n",
      "9 LLC write access\n",
      "10 LLC write miss\n",
      "11 LLC prefetch access\n",
      "12 LLC prefetch miss\n",
      "13 DTLB read access\n",
      "14 DTLB read miss\n",
      "15 DTLB write access\n",
      "16 DTLB write miss\n",
      "17 ITLB read access\n",
      "18 ITLB read miss\n",
      "19 BPU read access\n",
      "20 BPU read miss\n",
      "21 Cache node read access\n",
      "22 Cache node read miss\n",
      "23 Cache node write access\n",
      "24 Cache node write miss\n",
      "25 Cache node prefetch access\n",
      "26 Cache node prefetch miss\n",
      "27 cycles\n",
      "28 branch instructions\n",
      "29 branch prediction miss\n",
      "30 page faults\n",
      "31 context switch\n",
      "32 stall_during_issue\n",
      "33 stall_during_retirement\n",
      "34 Time stamp\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "if '/home/zechengh/Mastik/ad/detector/' not in sys.path:\n",
    "    sys.path.append('/home/zechengh/Mastik/ad/detector/')\n",
    "from collections import OrderedDict\n",
    "    \n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import utils\n",
    "import ADbenchmark\n",
    "import LSTMAD\n",
    "\n",
    "import json\n",
    "import collections\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Do not write .pyc\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "# Reload code when code is changed\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "id_to_feature = utils.id_to_feature\n",
    "for k, v in id_to_feature.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used features:\n",
      "Ins\n",
      "stall_during_issue\n",
      "stall_during_retirement\n",
      "cycles\n",
      "L1D read access (# load)\n",
      "DTLB read access\n",
      "L1D write access (# store)\n",
      "BPU read access\n",
      "DTLB write access\n",
      "branch instructions\n",
      "L1D read miss\n",
      "L1I read miss\n",
      "context switch\n"
     ]
    }
   ],
   "source": [
    "id_to_feature = utils.id_to_feature\n",
    "data = collections.defaultdict(collections.defaultdict)\n",
    "\n",
    "for bg_program in ['none', 'mysql', 'webserver', 'streamserver', 'mltrain', 'mapreduce']:\n",
    "    data_dir = 'perf/data/{bg_program}_same_core/10000us/'.format(bg_program=bg_program)\n",
    "    for f in os.listdir(data_dir):\n",
    "        if f.endswith('.npy'):\n",
    "            file_name = f.split('.')[0]\n",
    "            data[bg_program][file_name] = np.load(os.path.join(data_dir, f))\n",
    "\n",
    "feature_list = utils.FeatureSelect.feature_list\n",
    "\n",
    "print(\"Used features:\")\n",
    "for i in feature_list:\n",
    "    print(id_to_feature[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 35)\n",
      "(55000, 35)\n",
      "(55000, 35)\n"
     ]
    }
   ],
   "source": [
    "data_merged_train = np.concatenate(\n",
    "    [\n",
    "        data['mltrain']['train_normal'],\n",
    "        data['mysql']['train_normal'],\n",
    "        data['streamserver']['train_normal'],\n",
    "        data['webserver']['train_normal'],\n",
    "        data['mapreduce']['train_normal'],\n",
    "    ],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "data_merged_ref_and_val_normal = np.concatenate(\n",
    "    [\n",
    "        data['mltrain']['ref_and_val_normal'],\n",
    "        data['mysql']['ref_and_val_normal'],\n",
    "        data['streamserver']['ref_and_val_normal'],\n",
    "        data['webserver']['ref_and_val_normal'],\n",
    "        data['mapreduce']['ref_and_val_normal'],\n",
    "    ],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "data_merged_test = np.concatenate(\n",
    "    [\n",
    "        data['mltrain']['test_normal'],\n",
    "        data['mysql']['test_normal'],\n",
    "        data['streamserver']['test_normal'],\n",
    "        data['webserver']['test_normal'],\n",
    "        data['mapreduce']['test_normal']\n",
    "    ],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "print(data_merged_train.shape)\n",
    "print(data_merged_ref_and_val_normal.shape)\n",
    "print(data_merged_test.shape)\n",
    "\n",
    "np.save('perf/data/merged/10000us/train_normal.npy', data_merged_train)\n",
    "np.save('perf/data/merged/10000us/ref_and_val_normal.npy', data_merged_ref_and_val_normal)\n",
    "np.save('perf/data/merged/10000us/test_normal.npy', data_merged_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python3 LSTMAD.py --training --data_dir ../perf/data/merged/10000us/ --save_model_name AnomalyDetectorMerged.ckpt --gpu --Nhidden 256 --LearningRate 1e-2 --Nbatches 100 --RED_points 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
